{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646819c5",
   "metadata": {},
   "source": [
    "# **Amazon Lookout for Equipment**\n",
    "*Part 5 - Scheduling regular inference calls*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77700dd7",
   "metadata": {},
   "source": [
    "### Notebook configuration update\n",
    "Let's make sure that we have access to the latest version of the AWS Python packages. If you see a `pip` dependency error, check that the `boto3` version is ok: if it's greater than 1.17.48 (the first version that includes the `lookoutequipment` API), you can discard this error and move forward with the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edff0f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3 version: 1.18.28 (should be >= 1.17.48 to include Lookout for Equipment API)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "print(f'boto3 version: {boto3.__version__} (should be >= 1.17.48 to include Lookout for Equipment API)')\n",
    "\n",
    "# Restart the current notebook to ensure we take into account the previous updates:\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251feadc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b766fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Helper functions for managing Lookout for Equipment API calls:\n",
    "sys.path.append('../utils')\n",
    "import lookout_equipment_utils as lookout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611041e",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "266cc484",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_ARN                 = sagemaker.get_execution_role()\n",
    "REGION_NAME              = boto3.session.Session().region_name\n",
    "BUCKET                   = config.BUCKET\n",
    "PREFIX                   = config.PREFIX_INFERENCE\n",
    "INFERENCE_SCHEDULER_NAME = config.INFERENCE_SCHEDULER_NAME\n",
    "MODEL_NAME               = config.MODEL_NAME\n",
    "ASSET_ID                 = config.ASSET_ID\n",
    "\n",
    "TMP_DATA       = os.path.join('..', 'data', 'interim', ASSET_ID)\n",
    "PROCESSED_DATA = os.path.join('..', 'data', 'processed', ASSET_ID)\n",
    "INFERENCE_DATA = os.path.join(PROCESSED_DATA, 'inference-data') \n",
    "TRAIN_DATA     = os.path.join(PROCESSED_DATA, 'training-data', 'centrifugal-pump')\n",
    "\n",
    "os.makedirs(INFERENCE_DATA, exist_ok=True)\n",
    "os.makedirs(os.path.join(INFERENCE_DATA, 'input'), exist_ok=True)\n",
    "os.makedirs(os.path.join(INFERENCE_DATA, 'output'), exist_ok=True)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('Solarize_Light2')\n",
    "plt.rcParams['lines.linewidth'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907bba79",
   "metadata": {},
   "source": [
    "## Create an inference scheduler\n",
    "---\n",
    "While navigating to the model details part of the console, you will see that you have no inference scheduled yet:\n",
    "\n",
    "![Schedule Starting point](assets/schedule_start.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5257454d",
   "metadata": {},
   "source": [
    "### Scheduler configuration\n",
    "Let's create a new inference schedule: some parameters are mandatory, while others offer some added flexibility.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "* Set `DATA_UPLOAD_FREQUENCY` at which the data will be uploaded for inference. Allowed values are `PT5M`, `PT10M`, `PT15M`, `PT30M` and `PT1H`.\n",
    "  * This is both the frequency of the inference scheduler and how often data are uploaded to the source bucket.\n",
    "  *  **Note**: ***the upload frequency must be compatible with the sampling rate selected at training time.*** *For example, if a model was trained with a 30 minutes resampling, asking for 5 minutes won't work and you need to select either PT30M and PT1H for this parameter at inference time.*\n",
    "* Set `INFERENCE_DATA_SOURCE_BUCKET` to the S3 bucket of your inference data\n",
    "* Set `INFERENCE_DATA_SOURCE_PREFIX` to the S3 prefix of your inference data\n",
    "* Set `INFERENCE_DATA_OUTPUT_BUCKET` to the S3 bucket where you want inference results\n",
    "* Set `INFERENCE_DATA_OUTPUT_PREFIX` to the S3 prefix where you want inference results\n",
    "* Set `ROLE_ARN_FOR_INFERENCE` to the role to be used to **read** data to infer on and **write** inference output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4f6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the model on which you want to create this inference scheduler\n",
    "MODEL_NAME_FOR_CREATING_INFERENCE_SCHEDULER = MODEL_NAME\n",
    "\n",
    "# Mandatory parameters:\n",
    "INFERENCE_DATA_SOURCE_BUCKET = BUCKET\n",
    "INFERENCE_DATA_SOURCE_PREFIX = f'{PREFIX}/input/'\n",
    "INFERENCE_DATA_OUTPUT_BUCKET = BUCKET\n",
    "INFERENCE_DATA_OUTPUT_PREFIX = f'{PREFIX}/output/'\n",
    "ROLE_ARN_FOR_INFERENCE = ROLE_ARN\n",
    "DATA_UPLOAD_FREQUENCY = 'PT5M'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e78a64",
   "metadata": {},
   "source": [
    "#### Time zone parameter (optional)\n",
    "\n",
    "You can set `INPUT_TIMEZONE_OFFSET` to the following allowed values: `+00:00`, `+00:30`, `+01:00`, ... `+11:30`, `+12:00`, `-00:00`, `-00:30`, `-01:00`, ... `-11:30`, `-12:00`.\n",
    "\n",
    "This is the timezone the scheduler will use to find the input files to run inference for. A timezone's offset refers to how many hours the timezone is from Coordinated Universal Time (UTC).\n",
    "\n",
    "Let's take an example:\n",
    "* The current date April 5th, 2021 and time is 1pm UTC\n",
    "* You're in India, which is 5 hour 30 ahead of UTC and you set the `INPUT_TIMEZONE_OFFSET` to `+05:30`\n",
    "* If the scheduler wakes up at 1pm UTC, A filename called 20210405**1830**00 will be found (1pm + 5H30 = 6.30pm)\n",
    "\n",
    "Use the following cell to convert time zone identifier (`Europe/Paris`, `US/Central`...) to a time zone offset. You can build a timezone object by leveraging the World Timezone Definition **[available here](https://gist.github.com/heyalexej/8bf688fd67d7199be4a1682b3eec7568)** or by listing the available ones using this code snippet:\n",
    "```python\n",
    "import pytz\n",
    "for tz in pytz.all_timezones:\n",
    "    print tz\n",
    "```\n",
    "If you want to use universal time, replace the timezone string below (`Asia/Calcutta`) by `UTC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a912823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utc_timezone = pytz.timezone(\"UTC\")\n",
    "current_timezone = pytz.timezone(\"Etc/UTC\")\n",
    "tz_offset = datetime.datetime.now(current_timezone).strftime('%z')\n",
    "INPUT_TIMEZONE_OFFSET = tz_offset[:3] + ':' + tz_offset[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc451d15",
   "metadata": {},
   "source": [
    "#### Other optional parameters\n",
    "\n",
    "* Set `DATA_DELAY_OFFSET_IN_MINUTES` to the number of minutes you expect the data to be delayed to upload. It's a time buffer to upload data.\n",
    "* Set `TIMESTAMP_FORMAT`. The allowed values `EPOCH`, `yyyy-MM-dd-HH-mm-ss` or `yyyyMMddHHmmss`. This is the format of timestamp which is the suffix of the input data file name. This is used by Lookout Equipment to understand which files to run inference on (so that you don't need to remove previous files to let the scheduler finds which one to run on).\n",
    "* Set `COMPONENT_TIMESTAMP_DELIMITER`. The allowed values `-`, `_` or ` `. This is the delimiter character that is used to separate the component from the timestamp in the input filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4541810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DELAY_OFFSET_IN_MINUTES = 2\n",
    "COMPONENT_TIMESTAMP_DELIMITER = '_'\n",
    "TIMESTAMP_FORMAT = 'yyyyMMddHHmmss'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0af6f0",
   "metadata": {},
   "source": [
    "### Create the inference scheduler\n",
    "The CreateInferenceScheduler API creates a scheduler **and** starts it: this means that this starts costing you right away. However, you can stop and start an existing scheduler at will (see at the end of this notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85066055",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lookout.LookoutEquipmentScheduler(\n",
    "    scheduler_name=INFERENCE_SCHEDULER_NAME,\n",
    "    model_name=MODEL_NAME_FOR_CREATING_INFERENCE_SCHEDULER,\n",
    "    region_name=REGION_NAME\n",
    ")\n",
    "\n",
    "scheduler_params = {\n",
    "    'input_bucket': INFERENCE_DATA_SOURCE_BUCKET,\n",
    "    'input_prefix': INFERENCE_DATA_SOURCE_PREFIX,\n",
    "    'output_bucket': INFERENCE_DATA_OUTPUT_BUCKET,\n",
    "    'output_prefix': INFERENCE_DATA_OUTPUT_PREFIX,\n",
    "    'role_arn': ROLE_ARN_FOR_INFERENCE,\n",
    "    'upload_frequency': DATA_UPLOAD_FREQUENCY,\n",
    "    'delay_offset': DATA_DELAY_OFFSET_IN_MINUTES,\n",
    "    'timezone_offset': INPUT_TIMEZONE_OFFSET,\n",
    "    'component_delimiter': COMPONENT_TIMESTAMP_DELIMITER,\n",
    "    'timestamp_format': TIMESTAMP_FORMAT\n",
    "}\n",
    "\n",
    "scheduler.set_parameters(**scheduler_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded2f184",
   "metadata": {},
   "source": [
    "Now that we defined `scheduler_params`, let's create the scheduler by running:\n",
    "\n",
    "```python\n",
    "create_scheduler_response = lookout_client.create_inference_scheduler({\n",
    "    'ClientToken': uuid.uuid4().hex\n",
    "})\n",
    "```\n",
    "\n",
    "The following method encapsulates the call to the [**CreateInferenceScheduler**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_CreateInferenceScheduler.html) API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e06cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Polling Inference Scheduler Status =====\n",
      "\n",
      "Scheduler Status: PENDING\n",
      "Scheduler Status: RUNNING\n",
      "\n",
      "===== End of Polling Inference Scheduler Status =====\n"
     ]
    }
   ],
   "source": [
    "create_scheduler_response = scheduler.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0a100",
   "metadata": {},
   "source": [
    "Our scheduler is now running and its inference history is currently empty:\n",
    "\n",
    "![Scheduler created](assets/schedule_created.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65359be",
   "metadata": {},
   "source": [
    "## Get inference results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b964a",
   "metadata": {},
   "source": [
    "### List inference executions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8d287d",
   "metadata": {},
   "source": [
    "**Let's now wait for 5-15 minutes to give some time to the scheduler to run its first inferences.** Once the wait is over, we can use the ListInferenceExecution API for our current inference scheduler. The only mandatory parameter is the scheduler name.\n",
    "\n",
    "You can also choose a time period for which you want to query inference executions for. If you don't specify it, then all executions for an inference scheduler will be listed. If you want to specify the time range, you can do this:\n",
    "\n",
    "```python\n",
    "START_TIME_FOR_INFERENCE_EXECUTIONS = datetime.datetime(2010,1,3,0,0,0)\n",
    "END_TIME_FOR_INFERENCE_EXECUTIONS = datetime.datetime(2010,1,5,0,0,0)\n",
    "```\n",
    "\n",
    "Which means the executions after `2010-01-03 00:00:00` and before `2010-01-05 00:00:00` will be listed.\n",
    "\n",
    "You can also choose to query for executions in particular status, the allowed status are `IN_PROGRESS`, `SUCCESS` and `FAILED`.\n",
    "\n",
    "The following cell use `scheduler.list_inference_executions()` as a wrapper around the [**ListInferenceExecutions**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_ListInferenceExecutions.html) API:\n",
    "\n",
    "```python\n",
    "    list_executions_response = lookout_client.list_inference_executions({\n",
    "        \"MaxResults\": 50,\n",
    "        \"InferenceSchedulerName\": INFERENCE_SCHEDULER_NAME,\n",
    "        \"Status\": EXECUTION_STATUS,\n",
    "        \"DataStartTimeAfter\": START_TIME_FOR_INFERENCE_EXECUTIONS,\n",
    "        \"DataEndTimeBefore\": END_TIME_FOR_INFERENCE_EXECUTIONS\n",
    "    })\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81a827e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAITING FOR THE FIRST INFERENCE EXECUTION\n",
      "WAITING FOR THE FIRST INFERENCE EXECUTION\n",
      "WAITING FOR THE FIRST INFERENCE EXECUTION\n",
      "WAITING FOR THE FIRST INFERENCE EXECUTION\n",
      "FIRST INFERENCE EXECUTED\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ModelName': 'f866f7a1-767b-4eca-a340-fa4ea4bdbba6-model',\n",
       "  'ModelArn': 'arn:aws:lookoutequipment:us-east-1:631071447677:model/f866f7a1-767b-4eca-a340-fa4ea4bdbba6-model/9f147714-821a-4a03-9979-0bc8f4b2da5d',\n",
       "  'InferenceSchedulerName': 'f866f7a1-767b-4eca-a340-fa4ea4bdbba6-scheduler',\n",
       "  'InferenceSchedulerArn': 'arn:aws:lookoutequipment:us-east-1:631071447677:inference-scheduler/f866f7a1-767b-4eca-a340-fa4ea4bdbba6-scheduler/65a8a335-3d97-4167-a0f8-2ac1b4189379',\n",
       "  'ScheduledStartTime': datetime.datetime(2021, 9, 1, 15, 32, tzinfo=tzlocal()),\n",
       "  'DataStartTime': datetime.datetime(2021, 9, 1, 15, 25, tzinfo=tzlocal()),\n",
       "  'DataEndTime': datetime.datetime(2021, 9, 1, 15, 30, tzinfo=tzlocal()),\n",
       "  'DataInputConfiguration': {'S3InputConfiguration': {'Bucket': 'l4ef866f-asset1-train-inference',\n",
       "    'Prefix': 'f866f7a1-767b-4eca-a340-fa4ea4bdbba6/inference-data/input/'}},\n",
       "  'DataOutputConfiguration': {'S3OutputConfiguration': {'Bucket': 'l4ef866f-asset1-train-inference',\n",
       "    'Prefix': 'f866f7a1-767b-4eca-a340-fa4ea4bdbba6/inference-data/output/'}},\n",
       "  'CustomerResultObject': {'Bucket': 'l4ef866f-asset1-train-inference',\n",
       "   'Key': 'f866f7a1-767b-4eca-a340-fa4ea4bdbba6/inference-data/output/2021-09-01T15:25:00Z/results.jsonl'},\n",
       "  'Status': 'SUCCESS'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_TIME_FOR_INFERENCE_EXECUTIONS = None\n",
    "END_TIME_FOR_INFERENCE_EXECUTIONS = None\n",
    "EXECUTION_STATUS = None\n",
    "\n",
    "execution_summaries = []\n",
    "\n",
    "while len(execution_summaries) == 0:\n",
    "    execution_summaries = scheduler.list_inference_executions(\n",
    "        start_time=START_TIME_FOR_INFERENCE_EXECUTIONS,\n",
    "        end_time=END_TIME_FOR_INFERENCE_EXECUTIONS,\n",
    "        execution_status=EXECUTION_STATUS\n",
    "    )\n",
    "    if len(execution_summaries) == 0:\n",
    "        print('WAITING FOR THE FIRST INFERENCE EXECUTION')\n",
    "        time.sleep(60)\n",
    "        \n",
    "    else:\n",
    "        print('FIRST INFERENCE EXECUTED\\n')\n",
    "        break\n",
    "            \n",
    "execution_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e6b290",
   "metadata": {},
   "source": [
    "We have configured this scheduler to run every five minutes. After at least 5 minutes we can also see the history in the console populated with its first few executions: after an hour or so, we will see that the last one failed as we only generated 10 files above and the scheduler did find the last one at the time it was fired:\n",
    "\n",
    "![Inference history](assets/schedule_inference_history.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22318361",
   "metadata": {},
   "source": [
    "When the scheduler starts (for example at `datetime.datetime(2021, 1, 27, 9, 15)`, it looks for **a single** CSV file located in the input location with a filename that contains a timestamp set to the previous step. For example, a file named:\n",
    "\n",
    "* centrifugal-pump_2021012709**10**00.csv will be found and ingested\n",
    "* centrifugal-pump_2021012708**15**00.csv will **not be** ingested (it will be ingested at the next inference execution however)\n",
    "\n",
    "In addition, when opening the file `centrifugal-pump_20210127091000.csv`, it will look for any row with a date that is between the `DataStartTime` and the `DataEndTime` of the inference execution. If it doesn't find such a row, an exception will be thrown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd558f9",
   "metadata": {},
   "source": [
    "### Download inference results\n",
    "Let's have a look at the content now available in the scheduler output location: each inference execution creates a subfolder in the output directory. The subfolder name is the timestamp (GMT) at which the inference was executed and it contains a single [JSON lines](https://jsonlines.org/) file named `results.jsonl`:\n",
    "\n",
    "![Inference input](assets/schedule_inference_output_data.png)\n",
    "\n",
    "Each execution summary is a JSON document that has the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "babaa23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelName': 'f866f7a1-767b-4eca-a340-fa4ea4bdbba6-model',\n",
       " 'ModelArn': 'arn:aws:lookoutequipment:us-east-1:631071447677:model/f866f7a1-767b-4eca-a340-fa4ea4bdbba6-model/9f147714-821a-4a03-9979-0bc8f4b2da5d',\n",
       " 'InferenceSchedulerName': 'f866f7a1-767b-4eca-a340-fa4ea4bdbba6-scheduler',\n",
       " 'InferenceSchedulerArn': 'arn:aws:lookoutequipment:us-east-1:631071447677:inference-scheduler/f866f7a1-767b-4eca-a340-fa4ea4bdbba6-scheduler/65a8a335-3d97-4167-a0f8-2ac1b4189379',\n",
       " 'ScheduledStartTime': datetime.datetime(2021, 9, 1, 15, 32, tzinfo=tzlocal()),\n",
       " 'DataStartTime': datetime.datetime(2021, 9, 1, 15, 25, tzinfo=tzlocal()),\n",
       " 'DataEndTime': datetime.datetime(2021, 9, 1, 15, 30, tzinfo=tzlocal()),\n",
       " 'DataInputConfiguration': {'S3InputConfiguration': {'Bucket': 'l4ef866f-asset1-train-inference',\n",
       "   'Prefix': 'f866f7a1-767b-4eca-a340-fa4ea4bdbba6/inference-data/input/'}},\n",
       " 'DataOutputConfiguration': {'S3OutputConfiguration': {'Bucket': 'l4ef866f-asset1-train-inference',\n",
       "   'Prefix': 'f866f7a1-767b-4eca-a340-fa4ea4bdbba6/inference-data/output/'}},\n",
       " 'CustomerResultObject': {'Bucket': 'l4ef866f-asset1-train-inference',\n",
       "  'Key': 'f866f7a1-767b-4eca-a340-fa4ea4bdbba6/inference-data/output/2021-09-01T15:25:00Z/results.jsonl'},\n",
       " 'Status': 'SUCCESS'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution_summaries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef9589",
   "metadata": {},
   "source": [
    "When the `Status` key from the previous JSON result is set to `SUCCESS`, you can collect the results location in the `CustomerResultObject` field. We are now going to loop through each execution result and download each JSON lines files generated by the scheduler. Then we will insert their results into an overall dataframe for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3eba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-01 15:26:00</th>\n",
       "      <td>0</td>\n",
       "      <td>NO_ANOMALY_DETECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 15:27:00</th>\n",
       "      <td>0</td>\n",
       "      <td>NO_ANOMALY_DETECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 15:28:00</th>\n",
       "      <td>0</td>\n",
       "      <td>NO_ANOMALY_DETECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 15:29:00</th>\n",
       "      <td>0</td>\n",
       "      <td>NO_ANOMALY_DETECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 15:30:00</th>\n",
       "      <td>0</td>\n",
       "      <td>NO_ANOMALY_DETECTED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     prediction    prediction_reason\n",
       "timestamp                                           \n",
       "2021-09-01 15:26:00           0  NO_ANOMALY_DETECTED\n",
       "2021-09-01 15:27:00           0  NO_ANOMALY_DETECTED\n",
       "2021-09-01 15:28:00           0  NO_ANOMALY_DETECTED\n",
       "2021-09-01 15:29:00           0  NO_ANOMALY_DETECTED\n",
       "2021-09-01 15:30:00           0  NO_ANOMALY_DETECTED"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the list of execution summaries in case all executions were not captured yet:\n",
    "_ = scheduler.list_inference_executions()\n",
    "\n",
    "# Loops through the executions summaries:\n",
    "results_json = []\n",
    "for execution_summary in scheduler.execution_summaries:\n",
    "    print('.', end='')\n",
    "    \n",
    "    # We only get an output if the inference execution is a sucess:\n",
    "    status = execution_summary['Status']\n",
    "    if status == 'SUCCESS':\n",
    "        # Download the JSON-line file locally:\n",
    "        bucket = execution_summary['CustomerResultObject']['Bucket']\n",
    "        key = execution_summary['CustomerResultObject']['Key']\n",
    "        current_timestamp = key.split('/')[-2]\n",
    "        local_fname = os.path.join(INFERENCE_DATA, 'output', f'centrifugal-pump_{current_timestamp}.jsonl')\n",
    "        s3_fname = f's3://{bucket}/{key}'\n",
    "        \n",
    "        !aws s3 cp --quiet $s3_fname $local_fname\n",
    "        \n",
    "        # Opens the file and concatenate the results into a dataframe:\n",
    "        with open(local_fname, 'r') as f:\n",
    "            content = [eval(line) for line in f.readlines()]\n",
    "            results_json = results_json + content\n",
    "    \n",
    "# Build the final dataframes with all the results:\n",
    "results_df = pd.DataFrame(results_json)\n",
    "results_df['timestamp'] = pd.to_datetime(results_df['timestamp'])\n",
    "results_df = results_df.set_index('timestamp')\n",
    "results_df = results_df.sort_index()\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c881e731",
   "metadata": {},
   "source": [
    "The content of each JSON lines file follows this format:\n",
    "    \n",
    "```json\n",
    "[\n",
    "    {\n",
    "        'timestamp': '2021-04-07T20:00:00.000000',\n",
    "        'prediction': 1,\n",
    "        'diagnostics': [\n",
    "            {'name': 'centrifugal-pump\\\\Sensor0', 'value': 0.12},\n",
    "            {'name': 'centrifugal-pump\\\\Sensor1', 'value': 0.0},\n",
    "            {'name': 'centrifugal-pump\\\\Sensor2', 'value': 0.0},\n",
    "                                  .\n",
    "                                  .\n",
    "                                  .\n",
    "            {'name': 'centrifugal-pump\\\\Sensor27', 'value': 0.08},\n",
    "            {'name': 'centrifugal-pump\\\\Sensor28', 'value': 0.02},\n",
    "            {'name': 'centrifugal-pump\\\\Sensor29', 'value': 0.02}\n",
    "        ]\n",
    "    }\n",
    "    ...\n",
    "]\n",
    "```\n",
    "Each timestamp found in the file is associated to a prediction: 1 when an anomaly is detected an 0 otherwise. When the `prediction` field is 1 (an anomaly is detected), the `diagnostics` field contains each sensor (with the format `component`\\\\`tag`) and an associated percentage. This percentage corresponds to the magnitude of impact of a given sensor to the detected anomaly. For instance, in the example above, the tag `Sensor0` located on the `centrifugal-pump` component has an estimated 12% magnitude of impact to the anomaly detected at 8pm on April 7th 2021. This dataset has 122 sensors: if each sensor contributed the same way to this event, the impact of each of them would be `100 / 122 = 0.82%`, so 12% is indeed statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86486491",
   "metadata": {},
   "source": [
    "---\n",
    "### Visualizing the inference results\n",
    "#### Single inference analysis\n",
    "Let's first expand the results to expose the content of the **diagnostics** column above into different dataframe columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ee2657f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-01 15:26:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 15:27:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 15:28:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 15:29:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 15:30:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     prediction\n",
       "timestamp                      \n",
       "2021-09-01 15:26:00           0\n",
       "2021-09-01 15:27:00           0\n",
       "2021-09-01 15:28:00           0\n",
       "2021-09-01 15:29:00           0\n",
       "2021-09-01 15:30:00           0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_results = []\n",
    "for index, row in results_df.iterrows():\n",
    "    new_row = dict()\n",
    "    new_row.update({'timestamp': index})\n",
    "    new_row.update({'prediction': row['prediction']})\n",
    "    \n",
    "    if row['prediction'] == 1:\n",
    "        diagnostics = pd.DataFrame(row['diagnostics'])\n",
    "        diagnostics = dict(zip(diagnostics['name'], diagnostics['value']))\n",
    "        new_row = {**new_row, **diagnostics}\n",
    "        \n",
    "    expanded_results.append(new_row)\n",
    "    \n",
    "expanded_results = pd.DataFrame(expanded_results)\n",
    "expanded_results['timestamp'] = pd.to_datetime(expanded_results['timestamp'])\n",
    "expanded_results = expanded_results.set_index('timestamp')\n",
    "expanded_results\n",
    "# expanded_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f452ad0d",
   "metadata": {},
   "source": [
    "Each detected event have some detailed diagnostics. Let's unpack the details for the first event and plot a similar bar chart than what the console provides when it evaluates a trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a95e80fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "event_details = pd.DataFrame(expanded_results.iloc[0, 1:]).reset_index()\n",
    "event_details.columns = ['name', 'value']\n",
    "event_details = event_details.sort_values(by='value')\n",
    "\n",
    "# We can then plot a horizontal bar chart:\n",
    "y_pos = np.arange(event_details.shape[0])\n",
    "values = list(event_details['value'])\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.barh(y_pos, event_details['value'], align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(event_details['name'])\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "# Add the values in each bar:\n",
    "for i, v in enumerate(values):\n",
    "    if v == 0:\n",
    "        ax.text(0.0005, i, f'{v*100:.2f}%', color='#000000', verticalalignment='center')\n",
    "    else:\n",
    "        ax.text(0.0005, i, f'{v*100:.2f}%', color='#FFFFFF', fontweight='bold', verticalalignment='center')\n",
    "    \n",
    "plt.title(f'Event detected at {expanded_results.index[0]}', fontsize=12, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b53787",
   "metadata": {},
   "source": [
    "As we did in the previous notebook, the above bar chart is already of great help to pinpoint what might be going wrong with your asset. Let's load the initial tags description file we prepared in the first notebook and match the sensors with our initial components to group sensors by component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f74b1e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7fd9330f3c20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtags_description_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTMP_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tags_description.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtags_description_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags_description_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevent_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sensor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\\'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcomponent_diagnostics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_description_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sensor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Tag'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Component'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcomponent_diagnostics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent_diagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Component'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3039\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3040\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3041\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3066\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3067\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3068\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3069\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# Agregate event diagnostics at the component level:\n",
    "tags_description_fname = os.path.join(TMP_DATA, 'tags_description.csv')\n",
    "tags_description_df = pd.read_csv(tags_description_fname)\n",
    "event_details[['asset', 'sensor']] = event_details['name'].str.split('\\\\', expand=True)\n",
    "component_diagnostics = pd.merge(event_details, tags_description_df, how='inner', left_on='sensor', right_on='Tag')[['name', 'value', 'Component']]\n",
    "component_diagnostics = component_diagnostics.groupby(by='Component').sum().sort_values(by='value')\n",
    "\n",
    "# Prepare Y position and values for bar chart:\n",
    "y_pos = np.arange(component_diagnostics.shape[0])\n",
    "values = list(component_diagnostics['value'])\n",
    "\n",
    "# Plot the bar chart:\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.barh(y_pos, component_diagnostics['value'], align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(list(component_diagnostics.index))\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "# Add the values in each bar:\n",
    "for i, v in enumerate(values):\n",
    "    ax.text(0.005, i, f'{v*100:.2f}%', color='#FFFFFF', fontweight='bold', verticalalignment='center')\n",
    "    \n",
    "# Show the final plot:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400052a",
   "metadata": {},
   "source": [
    "#### Multiple inferences analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed877cc8",
   "metadata": {},
   "source": [
    "We can also plot the contribution evolution for the top contributing signals over a period of time: the following graph gives an example of what a real time dashboard could look like to expose the results of an Amazon Lookout for Equipment scheduler.\n",
    "\n",
    "**Note:** The plot stops after a while as there are no more anomaly detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = expanded_results.iloc[:, 1:]\n",
    "mean_contribution = df.mean().sort_values(ascending=False)\n",
    "filtered_sensors = mean_contribution.index.to_list()\n",
    "df = df.loc[:, filtered_sensors]\n",
    "\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "df.plot.area(ax=ax, stacked=False)#, colormap=\"jet\")\n",
    "plt.legend(loc='lower center', ncol=5, bbox_to_anchor=(0.5, -0.45))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba3499",
   "metadata": {},
   "source": [
    "The above plot is quite busy, let's filter on the signals that are, in average, **contributing the most** across this event and focus **only on the time range when something is happening**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688221d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the top 8 signals with the highest contribution to these events (in average):\n",
    "df = expanded_results.iloc[:, 1:].dropna()\n",
    "mean_contribution = df.mean().sort_values(ascending=False)\n",
    "filtered_sensors = mean_contribution[:8].index.to_list()\n",
    "df = df.loc[:, filtered_sensors]\n",
    "\n",
    "# Area plot:\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "df.plot.area(ax=ax, stacked=False)#, colormap=\"jet\")\n",
    "plt.legend(loc='lower center', ncol=4, bbox_to_anchor=(0.5, -0.25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaaeb09",
   "metadata": {},
   "source": [
    "**As previously, let's agregate these sensor data at the component level:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_index = pd.MultiIndex.from_frame(tags_description_df[['Component', 'Tag']])\n",
    "components_results = expanded_results.iloc[:, 1:].dropna().copy()\n",
    "components_results.columns = column_index\n",
    "components_results = components_results.groupby(axis=1, level='Component').sum()\n",
    "components_results.columns = list(components_results.columns)\n",
    "components_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b3833",
   "metadata": {},
   "source": [
    "It looks like the pump is the first area where an anomaly is visible before each component becomes more balanced in the way they contribute to this detected event. However, the sensors associated to **the pump stays at the very high level** along this particular event which may call to a specific course of action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c070d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "components_results.plot.area(ax=ax, stacked=False, colormap=\"terrain\")\n",
    "plt.legend(loc='lower center', ncol=5, bbox_to_anchor=(0.5, -0.20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d51300",
   "metadata": {},
   "source": [
    "## (Optional) Inference scheduler operations\n",
    "---\n",
    "### Stop inference scheduler\n",
    "**Be frugal**, running the scheduler is the main cost driver of Amazon Lookout for Equipment. Use the [**StopInferenceScheduler**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_StopInferenceScheduler.html) API to stop an already running inference scheduler:\n",
    "\n",
    "```python\n",
    "stop_scheduler_response = lookout_client.stop_inference_scheduler(\n",
    "    InferenceSchedulerName=INFERENCE_SCHEDULER_NAME\n",
    ")\n",
    "```\n",
    "\n",
    "The following method is a wrapper around this API call and will stop the periodic inference executions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a06d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c7670",
   "metadata": {},
   "source": [
    "### Start an inference scheduler\n",
    "You can restart any `STOPPED` inference scheduler using the [**StartInferenceScheduler**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_StartInferenceScheduler.html) API:\n",
    "\n",
    "```python\n",
    "start_scheduler_response = lookout_client.start_inference_scheduler(\n",
    "    InferenceSchedulerName=INFERENCE_SCHEDULER_NAME\n",
    ")\n",
    "```\n",
    "\n",
    "The following method is a wrapper around this API call and will start the periodic inference executions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d369d972",
   "metadata": {},
   "source": [
    "### Delete an inference scheduler\n",
    "You can delete a **stopped** scheduler you have no more use of: note that you can only have one scheduler per model.\n",
    "\n",
    "```python\n",
    "delete_scheduler_response = lookout_client.delete_inference_scheduler(\n",
    "    InferenceSchedulerName=INFERENCE_SCHEDULER_NAME\n",
    ")\n",
    "```\n",
    "\n",
    "The `scheduler.delete()` method is a wrapper around the [**DeleteInferenceScheduler**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_DeleteInferenceScheduler.html) API and will delete a stopped scheduler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ff34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler.stop()\n",
    "# scheduler.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7699504e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5474cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for visualizing markdowns programatically\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\n",
    "'''\n",
    "<span style=\"color:green\"><span style=\"font-size:50px\">**Success!**</span></span>\n",
    "<br/>\n",
    "In this notebook, we used the model created in part 3 of this notebook, configured a scheduler and extracted the predictions obtained after it executed a few inferences.\n",
    "\n",
    "We also showed how we could post-process the inference results to deliver better insights into the detected events.\n",
    "'''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
